{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c5f936e1-5f48-4dda-8cd8-2e6f89ff6f84",
   "metadata": {},
   "source": [
    "# Noch erledigen"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb7a8640-76a0-47e9-b9b5-c8753d2b4c07",
   "metadata": {},
   "source": [
    "- Methode zum Plotten der Trajektorie eines Fußgängers (ersten 8 Steps in anderer Farbe als die weiteren 12)\n",
    "- Methode zum Plotten der vorhergesagten Trajektorie vs ground trouth\n",
    "- Methode zum Plotten des Model losses over time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e4a7ed81-94ed-48c7-af50-931e2214919b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout # LSTM hat auch dropout argument"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fe03195-1f85-4d7d-b04b-0c4d6a28f551",
   "metadata": {},
   "source": [
    "# 0. Daten vorbereiten"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddcad8be-49e2-4240-8ce0-b532e44a61ae",
   "metadata": {},
   "source": [
    "Im ersten Schritt werden die Daten aus den einzelnen .txt Dateien ausgelesen und in ein gemeinsames Dataframe gepackt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4fc868c5-3f2e-4f9e-9410-fc0066b2ea4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = ['Timestamp', 'ID', 'X', 'Y']\n",
    "df = pd.DataFrame(columns = column_names)\n",
    "\n",
    "# durch jede .txt Datei im Ordner 'Data' iterieren, Daten einlesen und ans Dataframe anhängen\n",
    "for filename in os.listdir(\"Data/raw\"): \n",
    "    if filename.endswith(\".txt\"):\n",
    "        tmp_df = pd.read_csv(\"Data/raw/\" + filename, sep=\" \", header=None)\n",
    "        tmp_df.columns = column_names \n",
    "        df = df.append(tmp_df, ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e3c441e5-e8f8-42a8-81e6-c115054610b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>ID</th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>1.728</td>\n",
       "      <td>14.378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12</td>\n",
       "      <td>100</td>\n",
       "      <td>2.035</td>\n",
       "      <td>14.378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>24</td>\n",
       "      <td>100</td>\n",
       "      <td>2.342</td>\n",
       "      <td>14.378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>36</td>\n",
       "      <td>100</td>\n",
       "      <td>2.630</td>\n",
       "      <td>14.378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>48</td>\n",
       "      <td>100</td>\n",
       "      <td>2.937</td>\n",
       "      <td>14.416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108115</th>\n",
       "      <td>11424</td>\n",
       "      <td>273</td>\n",
       "      <td>-27.961</td>\n",
       "      <td>18.169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108116</th>\n",
       "      <td>11436</td>\n",
       "      <td>273</td>\n",
       "      <td>-28.388</td>\n",
       "      <td>17.967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108117</th>\n",
       "      <td>11448</td>\n",
       "      <td>273</td>\n",
       "      <td>-28.747</td>\n",
       "      <td>17.787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108118</th>\n",
       "      <td>11460</td>\n",
       "      <td>273</td>\n",
       "      <td>-29.107</td>\n",
       "      <td>17.608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108119</th>\n",
       "      <td>11472</td>\n",
       "      <td>273</td>\n",
       "      <td>-29.354</td>\n",
       "      <td>17.428</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>108120 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Timestamp   ID       X       Y\n",
       "0              0  100   1.728  14.378\n",
       "1             12  100   2.035  14.378\n",
       "2             24  100   2.342  14.378\n",
       "3             36  100   2.630  14.378\n",
       "4             48  100   2.937  14.416\n",
       "...          ...  ...     ...     ...\n",
       "108115     11424  273 -27.961  18.169\n",
       "108116     11436  273 -28.388  17.967\n",
       "108117     11448  273 -28.747  17.787\n",
       "108118     11460  273 -29.107  17.608\n",
       "108119     11472  273 -29.354  17.428\n",
       "\n",
       "[108120 rows x 4 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe58d019-c25e-4a64-934c-358c154501b8",
   "metadata": {},
   "source": [
    "# 1. Daten vorverarbeiten"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f79906b-7ed1-4a6c-9b3c-844b644a9707",
   "metadata": {},
   "source": [
    "## 1.1 Vereinheitlichen von IDs und Timestamps | Deltas zwischen zwei Zeitpunkten berechnen"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c6cfcd4-564d-4abe-ba55-a0c9ced66f11",
   "metadata": {},
   "source": [
    "In diesem Schritt werden die Daten vorverarbeitet. Darunter fällt das vergeben einer einzigartigen ID für jeden Datenpunkt (1 Datenpunkt besteht aus 20 Zeitpunkten), sowie das Vereinheitlichen der Timestamps. Da für uns nur die Reihenfolge der einzelnen Zeitpunkte von Interesse ist, der Abstand zwischen diesen auch immer gleich ist, können wir den Zeitpunkten die Werte 1-20 zuordnen (wobei zu Zeitpunkt 1 das erste mal x und y Wert erfasst wurde und bei Zeitpunkt 20 das letzte mal). </br>\n",
    "Außerdem werden in diesem Schritt für die X- und Y-Werte die relativen Änderungen zwischen zwei Zeitpunkten berechnet und den separaten Spalten 'dx' und 'dy' abgelegt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "827dd839-efa1-44da-82cd-82a84da02d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_id = 0\n",
    "prev_x = 0\n",
    "prev_y = 0\n",
    "for i, row in df.iterrows():\n",
    "    if i % 20 == 0:\n",
    "        curr_id += 1 # alle 20 Zeitpunkte erhöht sich die ID\n",
    "        prev_x = row.X\n",
    "        prev_y = row.Y\n",
    "    df.at[i, 'ID'] = curr_id\n",
    "    df.at[i, 'Timestamp'] = (i % 20) + 1\n",
    "    dx = row.X - prev_x\n",
    "    dy = row.Y - prev_y\n",
    "    prev_x = row.X\n",
    "    prev_y = row.Y\n",
    "    df.at[i, 'dx'] = round(dx, 3)\n",
    "    df.at[i, 'dy'] = round(dy, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6d76a331-3356-47f6-a316-5362714e1533",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>ID</th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "      <th>dx</th>\n",
       "      <th>dy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.728</td>\n",
       "      <td>14.378</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2.035</td>\n",
       "      <td>14.378</td>\n",
       "      <td>0.307</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2.342</td>\n",
       "      <td>14.378</td>\n",
       "      <td>0.307</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2.630</td>\n",
       "      <td>14.378</td>\n",
       "      <td>0.288</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2.937</td>\n",
       "      <td>14.416</td>\n",
       "      <td>0.307</td>\n",
       "      <td>0.038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108115</th>\n",
       "      <td>16</td>\n",
       "      <td>5406</td>\n",
       "      <td>-27.961</td>\n",
       "      <td>18.169</td>\n",
       "      <td>-0.449</td>\n",
       "      <td>-0.180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108116</th>\n",
       "      <td>17</td>\n",
       "      <td>5406</td>\n",
       "      <td>-28.388</td>\n",
       "      <td>17.967</td>\n",
       "      <td>-0.427</td>\n",
       "      <td>-0.202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108117</th>\n",
       "      <td>18</td>\n",
       "      <td>5406</td>\n",
       "      <td>-28.747</td>\n",
       "      <td>17.787</td>\n",
       "      <td>-0.359</td>\n",
       "      <td>-0.180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108118</th>\n",
       "      <td>19</td>\n",
       "      <td>5406</td>\n",
       "      <td>-29.107</td>\n",
       "      <td>17.608</td>\n",
       "      <td>-0.360</td>\n",
       "      <td>-0.179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108119</th>\n",
       "      <td>20</td>\n",
       "      <td>5406</td>\n",
       "      <td>-29.354</td>\n",
       "      <td>17.428</td>\n",
       "      <td>-0.247</td>\n",
       "      <td>-0.180</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>108120 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Timestamp    ID       X       Y     dx     dy\n",
       "0              1     1   1.728  14.378  0.000  0.000\n",
       "1              2     1   2.035  14.378  0.307  0.000\n",
       "2              3     1   2.342  14.378  0.307  0.000\n",
       "3              4     1   2.630  14.378  0.288  0.000\n",
       "4              5     1   2.937  14.416  0.307  0.038\n",
       "...          ...   ...     ...     ...    ...    ...\n",
       "108115        16  5406 -27.961  18.169 -0.449 -0.180\n",
       "108116        17  5406 -28.388  17.967 -0.427 -0.202\n",
       "108117        18  5406 -28.747  17.787 -0.359 -0.180\n",
       "108118        19  5406 -29.107  17.608 -0.360 -0.179\n",
       "108119        20  5406 -29.354  17.428 -0.247 -0.180\n",
       "\n",
       "[108120 rows x 6 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b62afdf5-e102-4d50-91a6-6188e113ca56",
   "metadata": {},
   "source": [
    "## 1.2 Aufteilen der Daten in Trainings-, Test- und Validierungsdaten"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53998638-f08a-4cc3-b317-37ad693f286d",
   "metadata": {},
   "source": [
    "Um **Data Leakage** zu vermeiden, werden die Daten zuerst in die drei separaten Sets aufgeteilt und dann für jede separat ein Scaler verwendet, um die Daten zu normalisieren."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4af04d37-9e26-4dbf-907a-d89443e4c217",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainingsdaten: \t 4326  ≙ 80%\n",
      "Validierungsdaten: \t 540  ≙ 10%\n",
      "Testdaten: \t\t 540  ≙ 10%\n"
     ]
    }
   ],
   "source": [
    "ids = np.array(df.ID.unique()) # alle IDs holen\n",
    "np.random.shuffle(ids) # IDs zufällig durchmischen\n",
    "\n",
    "test_percentage = valid_percentage = 0.1\n",
    "test_size = int(test_percentage * len(ids))\n",
    "valid_size = int(valid_percentage * len(ids))\n",
    "test_ids, valid_ids, train_ids = ids[:test_size], ids[test_size:test_size + valid_size], ids[test_size + valid_size:]\n",
    "print(\"Trainingsdaten: \\t\", len(train_ids), \" ≙ 80%\")\n",
    "print(\"Validierungsdaten: \\t\", len(valid_ids), \" ≙ 10%\")\n",
    "print(\"Testdaten: \\t\\t\", len(test_ids), \" ≙ 10%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3d14f99-19fc-4df0-a5a4-8e71f016985d",
   "metadata": {},
   "source": [
    "Der Hauptdatensatz (mit allen Daten) wird in die drei einzelnen Datensätze aufgeteilt und diese als .csv Dateien abgespeichert. Wurden dieser Split bereits schon einmal durchgeführt, so werden die bereits existierenden .csv Dateien eingelesen. Will man das neuronale Netz mit neuen Mischungen von Test-, Trainings- und Validierungsdaten probieren, so müssen einfach die drei .csv Dateien aus dem Ordner \"Data/datasplits/\" entfernt werden. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "a2e73dbb-dace-4f59-9ce0-7c2f16f7ea5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".csv Dateien existieren bereits und wurden eingelesen...\n"
     ]
    }
   ],
   "source": [
    "path_train = \"Data/datasplits/traindata.csv\"\n",
    "path_test = \"Data/datasplits/testdata.csv\"\n",
    "path_valid = \"Data/datasplits/validationdata.csv\"\n",
    "if not os.path.exists(path_train) or not os.path.exists(path_test) or not os.path.exists(path_valid):\n",
    "    df_train = df.copy()\n",
    "    for id in np.concatenate([test_ids, valid_ids]):\n",
    "        df_train = df_train.drop(df_train[df_train.ID == id].index)\n",
    "    df_test = df.copy()\n",
    "    for id in np.concatenate([train_ids, valid_ids]):\n",
    "        df_test = df_test.drop(df_test[df_test.ID == id].index)\n",
    "    df_valid = df.copy()\n",
    "    for id in np.concatenate([test_ids, train_ids]):\n",
    "        df_valid = df_valid.drop(df_valid[df_valid.ID == id].index)\n",
    "    df_train.to_csv(path_train, sep=',', index = False)\n",
    "    df_test.to_csv(path_test, sep=',', index = False)\n",
    "    df_valid.to_csv(path_valid, sep=',', index = False)\n",
    "    print(\"CSV Dateien wurden erstellt,,,\")\n",
    "else:\n",
    "    df_train = pd.read_csv(path_train, sep=\",\")\n",
    "    df_test = pd.read_csv(path_test, sep=',')\n",
    "    df_valid = pd.read_csv(path_valid, sep=',')\n",
    "    print(\".csv Dateien existieren bereits und wurden eingelesen...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "4eaf2676-c4de-4130-bd21-e3f7973475c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>ID</th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "      <th>dx</th>\n",
       "      <th>dy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>-11.633</td>\n",
       "      <td>18.006</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>-11.633</td>\n",
       "      <td>18.006</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>-11.633</td>\n",
       "      <td>18.006</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>-11.633</td>\n",
       "      <td>18.083</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>-11.633</td>\n",
       "      <td>18.083</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86515</th>\n",
       "      <td>16</td>\n",
       "      <td>5406</td>\n",
       "      <td>-27.961</td>\n",
       "      <td>18.169</td>\n",
       "      <td>-0.449</td>\n",
       "      <td>-0.180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86516</th>\n",
       "      <td>17</td>\n",
       "      <td>5406</td>\n",
       "      <td>-28.388</td>\n",
       "      <td>17.967</td>\n",
       "      <td>-0.427</td>\n",
       "      <td>-0.202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86517</th>\n",
       "      <td>18</td>\n",
       "      <td>5406</td>\n",
       "      <td>-28.747</td>\n",
       "      <td>17.787</td>\n",
       "      <td>-0.359</td>\n",
       "      <td>-0.180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86518</th>\n",
       "      <td>19</td>\n",
       "      <td>5406</td>\n",
       "      <td>-29.107</td>\n",
       "      <td>17.608</td>\n",
       "      <td>-0.360</td>\n",
       "      <td>-0.179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86519</th>\n",
       "      <td>20</td>\n",
       "      <td>5406</td>\n",
       "      <td>-29.354</td>\n",
       "      <td>17.428</td>\n",
       "      <td>-0.247</td>\n",
       "      <td>-0.180</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>86520 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Timestamp    ID       X       Y     dx     dy\n",
       "0              1     3 -11.633  18.006  0.000  0.000\n",
       "1              2     3 -11.633  18.006  0.000  0.000\n",
       "2              3     3 -11.633  18.006  0.000  0.000\n",
       "3              4     3 -11.633  18.083  0.000  0.077\n",
       "4              5     3 -11.633  18.083  0.000  0.000\n",
       "...          ...   ...     ...     ...    ...    ...\n",
       "86515         16  5406 -27.961  18.169 -0.449 -0.180\n",
       "86516         17  5406 -28.388  17.967 -0.427 -0.202\n",
       "86517         18  5406 -28.747  17.787 -0.359 -0.180\n",
       "86518         19  5406 -29.107  17.608 -0.360 -0.179\n",
       "86519         20  5406 -29.354  17.428 -0.247 -0.180\n",
       "\n",
       "[86520 rows x 6 columns]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73311a62-b49a-4387-be85-4db814ec2642",
   "metadata": {},
   "source": [
    "Nun werden die Trainingsdaten so vorbereitet, dass man sie in das RNN einfüttern kann. Dazu brauchen sie die das Format [samples, time steps, features]. Nachdem wir später eine rekursive Single-Step Prediction für den nächsten Delta-Wert (basierend auf den 7 vorhergehenden) durchführen werden, muss man die Daten zusätzlich noch weiter aufteilen, was auch den Vorteil hat, dass man mehr Trainingsdaten hat. Jeder Datenpunkt wird in weitere Datenpunkte aufgeteilt, bestehend aus 7 Werten und der 8e Wert ist dann die erwartete Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "308aad9d-4ceb-4f50-ab3f-4f31a8c16697",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_length = 7 # Anhand von 7 dx und dy Werten (welche aus 8 Zeitschritten entstanden sind) sagen wir den nächsten Delta-Wert voraus\n",
    "\n",
    "def transform_traindata(df, sequence_length):\n",
    "    df = df.drop(df[df.Timestamp == 1].index) # Alle ersten Zeitschritte werden entfernt (da dx und dy hier eh immer 0 ist)\n",
    "    ids = np.array(df.ID.unique()) # alle (20 Timestep) Sequenzen aus dem dataframe holen, um die dann weiter aufzuteilen\n",
    "    x, y = [], []\n",
    "    for id in ids:\n",
    "        df_current = df[df.ID == id] # einen Datenpunkt mithilfe der ID herausgreifen und diesen dann in weitere Datenpunkte aufteilen\n",
    "        feature_data = np.array(df[['dx', 'dy']])\n",
    "        for i in range(sequence_length, feature_data.shape[0]):\n",
    "            x.append(feature_data[i-sequence_length:i,:]) #contains sequence_length values 0-sequence_length * columsn\n",
    "            y.append(feature_data[i, :]) #contains the prediction values for validation (3rd column = Close),  for single-step prediction\n",
    "    \n",
    "    x = np.array(x)\n",
    "    y = np.array(y)\n",
    "    return df, x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f4d57e0-ada4-4922-9709-af50641ff0f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, x_train, y_train = transform_traindata(df_train, sequence_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "9e47d218-3dea-4214-8715-88255b0a3605",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>ID</th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "      <th>dx</th>\n",
       "      <th>dy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>-11.633</td>\n",
       "      <td>18.006</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>-11.633</td>\n",
       "      <td>18.006</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>-11.633</td>\n",
       "      <td>18.083</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>-11.633</td>\n",
       "      <td>18.083</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>-11.633</td>\n",
       "      <td>18.083</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>-11.633</td>\n",
       "      <td>18.159</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>-11.633</td>\n",
       "      <td>18.159</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>-11.633</td>\n",
       "      <td>18.159</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>-11.633</td>\n",
       "      <td>18.255</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>-11.633</td>\n",
       "      <td>18.255</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>-11.633</td>\n",
       "      <td>18.255</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "      <td>-11.556</td>\n",
       "      <td>18.351</td>\n",
       "      <td>0.077</td>\n",
       "      <td>0.096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>3</td>\n",
       "      <td>-11.556</td>\n",
       "      <td>18.351</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "      <td>-11.556</td>\n",
       "      <td>18.351</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>3</td>\n",
       "      <td>-11.556</td>\n",
       "      <td>18.351</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "      <td>-11.556</td>\n",
       "      <td>18.351</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>3</td>\n",
       "      <td>-11.556</td>\n",
       "      <td>18.351</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>3</td>\n",
       "      <td>-11.556</td>\n",
       "      <td>18.351</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>-11.556</td>\n",
       "      <td>18.351</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Timestamp  ID       X       Y     dx     dy\n",
       "1           2   3 -11.633  18.006  0.000  0.000\n",
       "2           3   3 -11.633  18.006  0.000  0.000\n",
       "3           4   3 -11.633  18.083  0.000  0.077\n",
       "4           5   3 -11.633  18.083  0.000  0.000\n",
       "5           6   3 -11.633  18.083  0.000  0.000\n",
       "6           7   3 -11.633  18.159  0.000  0.076\n",
       "7           8   3 -11.633  18.159  0.000  0.000\n",
       "8           9   3 -11.633  18.159  0.000  0.000\n",
       "9          10   3 -11.633  18.255  0.000  0.096\n",
       "10         11   3 -11.633  18.255  0.000  0.000\n",
       "11         12   3 -11.633  18.255  0.000  0.000\n",
       "12         13   3 -11.556  18.351  0.077  0.096\n",
       "13         14   3 -11.556  18.351  0.000  0.000\n",
       "14         15   3 -11.556  18.351  0.000  0.000\n",
       "15         16   3 -11.556  18.351  0.000  0.000\n",
       "16         17   3 -11.556  18.351  0.000  0.000\n",
       "17         18   3 -11.556  18.351  0.000  0.000\n",
       "18         19   3 -11.556  18.351  0.000  0.000\n",
       "19         20   3 -11.556  18.351  0.000  0.000"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68f53fb0-88db-4dc5-9929-c52d794ed92a",
   "metadata": {},
   "source": [
    "## 1.3 Standardisieren"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1755d97-7118-4f04-9167-8de7ed277ad7",
   "metadata": {},
   "source": [
    "Durch die ersten 8 Werte erhalten wir 7 Deltas. Der erste Wert ist immer 0 (da wir ja keinen vorherigen Wert haben, um das Delta zu berechnen). Aus diesem Grund wird der erste Wert entfernt und dann später nur die sieben Delta-Werte in das NN gegeben."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d14c8bcb-3e0f-4dd3-ac73-f1e55ee90b8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard Scaler\n",
    "df_train_scaled = df_train.copy()\n",
    "df_train_scaled = df_train_scaled.drop(df_train_scaled[df_train_scaled.Timestamp == 1].index)\n",
    "scaler = StandardScaler() # = MinMaxScaler(feature_range = (-1,1)) oder RobustScaler()\n",
    "features = df_train_scaled[[\"dx\", \"dy\"]]\n",
    "scaler.fit(features)\n",
    "df_train_scaled[[\"dx_scaled\", \"dy_scaled\"]] = scaler.transform(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "248cab39-ee2b-4d07-83a1-96271e8b3018",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b4bea24-e587-4813-8be9-ee8260ad629b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# inverse the transform\n",
    "df_train_scaled[[\"dx_scaled\", \"dy_scaled\"]] = scaler.inverse_transform(df_train_scaled[[\"dx_scaled\", \"dy_scaled\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27504b54-38e6-4144-bebd-9d1385563ea5",
   "metadata": {},
   "source": [
    "# 2. Neuronales Netz trainieren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e20ce6c-8671-4280-9dd4-94418a1cebcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the neural network and its layers\n",
    "nn = Sequential()\n",
    "nn.add(LSTM(units = 50, return_sequences = True, input_shape = (X_train.shape[1], 1)))\n",
    "nn.add(Dense())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e6e1da4-f05b-4482-a795-8476c448baa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Man kann dem nn auch gleich die Validation daten mit dazu geben!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "281408a2-5a50-4afc-bd80-9a897c498c71",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cf683565-ae60-46cd-ac3c-a576d5ea1628",
   "metadata": {},
   "source": [
    "# Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fe4bfed-83e8-4245-a197-4891e1369526",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Plotting\"\"\"\n",
    "# x axis values\n",
    "x = np.array([3,2,1,4,5,6])\n",
    "# corresponding y axis values\n",
    "y = np.array([2,4,1,5,2,6])\n",
    "\n",
    "x2 = x * 2\n",
    "y2 = y * 2\n",
    "# plotting the points \n",
    "plt.plot(x, y, label = \"PersonA\", color='blue', linestyle='dotted', linewidth = 1,\n",
    "         marker='o', markerfacecolor='blue', markersize=5)\n",
    "plt.plot(x2, y2, label = \"LLL\", color='red', linestyle='dotted', linewidth = 1,\n",
    "         marker='o', markerfacecolor='red', markersize=5)\n",
    "# setting x and y axis range\n",
    "plt.ylim(np.amin(y) - 0.1, np.amax(y2) + 0.1)\n",
    "plt.xlim(np.amin(x) - 0.1, np.amax(x2) + 0.1)\n",
    "plt.legend(loc='best')\n",
    "  \n",
    "# naming the x axis\n",
    "plt.xlabel('x - axis')\n",
    "# naming the y axis\n",
    "plt.ylabel('y - axis')\n",
    "  \n",
    "# giving a title to my graph\n",
    "plt.title('Some cool customizations!')\n",
    "  \n",
    "# function to show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4550c51-0346-4c15-8504-b40b70a5760a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotten der Trajektorie eines einzelnen Fußgängers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47613e69-f6f3-4d34-bb80-9e17cc9485ea",
   "metadata": {},
   "source": [
    "# Normalize and standardize data\n",
    "You can normalize your dataset using the scikit-learn object MinMaxScaler.\n",
    "\n",
    "Good practice usage with the MinMaxScaler and other rescaling techniques is as follows:\n",
    "\n",
    "Fit the scaler using available training data. For normalization, this means the training data will be used to estimate the minimum and maximum observable values. This is done by calling the fit() function,\n",
    "Apply the scale to training data. This means you can use the normalized data to train your model. This is done by calling the transform() function\n",
    "Apply the scale to data going forward. This means you can prepare new data in the future on which you want to make predictions.\n",
    "If needed, the transform can be inverted. This is useful for converting predictions back into their original scale for reporting or plotting. This can be done by calling the inverse_transform() function.\n",
    "https://machinelearningmastery.com/normalize-standardize-time-series-data-python/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3ec596d-3b69-407d-a076-e1121f4564af",
   "metadata": {},
   "source": [
    "# k-Fold Cross Validation with validation set\n",
    "\n",
    "In general, when you are doing model selection and testing, your data is divided into three parts, training set, validation set and testing set. You use your training set to train different models, estimate the performance on your validation set, then select the model with optimal performance and test it on your testing set.\n",
    "\n",
    "On the other hand, if you are using K-fold cross-validation to estimate the performance of a model, your data is then divided into K folds, you loop through the K folds and each time use one fold as testing(or validation) set and use the rest (K-1) folds as training set. Then you average across all folds to get the estimated testing performance of your model. This is what the Wikipedia page is referring to.\n",
    "\n",
    "But keep in mind that this is for testing a specific model, if you have multiple candidate models and want to do model-selection as well, you have to select a model only with your training set to avoid this subtle circular logic fallacy. So you further divide your (K-1) folds 'training data' into two parts, one for training and one for validation. This means you do an extra 'cross-validation' first to select the optimal model within the (K-1) folds, and then you test this optimal model on your testing fold. In other words, you are doing a two-level cross-validation, one is the K-fold cross-validation in general, and within each cross-validation loop, there is an extra (K-1)-fold cross-validation for model selection. Then you have what you stated in your question, 'Of the k subsamples one subsample is retained as the validation data, one other subsample is retained as the test data, and k-2 subsamples are used as training data.'\n",
    "https://stats.stackexchange.com/questions/90288/in-k-fold-cross-validation-does-the-training-subsample-include-test-set\n",
    "\n",
    "## Why separate test and validation sets?\n",
    "The error rate estimate of the final model on validation data will be biased (smaller than the true error rate) since the validation set is used to select the final model After assessing the final model on the test set, YOU MUST NOT tune the model any further!\n",
    "https://stats.stackexchange.com/questions/19048/what-is-the-difference-between-test-set-and-validation-set"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
