{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "202113f4-c2d8-450d-8f60-d1377128427d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import Sequential\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.layers import LSTM, Dense, TimeDistributed, Dropout, Activation\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "# Creating the sample sinus curve dataset\n",
    "steps = 300\n",
    "gradient = 0.02\n",
    "list_a = []\n",
    "for i in range(0, steps, 1):\n",
    "    y = round(gradient * i + math.sin(math.pi * 0.125 * i), 5)\n",
    "    list_a.append(y)\n",
    "df = pd.DataFrame({\"valid\": list_a}, columns=[\"valid\"])\n",
    "\n",
    "# Visualizing the data\n",
    "fig, ax1 = plt.subplots(figsize=(16, 4))\n",
    "ax1.xaxis.set_major_locator(plt.MaxNLocator(30))\n",
    "plt.title(\"Sinus Data\")\n",
    "plt.plot(df[[\"valid\"]], color=\"#039dfc\", linewidth=3.0)\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38086425-17be-41ff-b260-6d0d4cc6b38e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eebae2d2-7c8e-4844-8c69-bdf9127146a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the number of rows in the data\n",
    "nrows = df.shape[0]\n",
    "\n",
    "# Convert the data to numpy values\n",
    "np_data_unscaled = np.array(df)\n",
    "np_data_unscaled = np.reshape(np_data_unscaled, (nrows, -1))\n",
    "print(np_data_unscaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b360e7fc-fdb7-4a30-bb2b-fed3ee3d6bd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform the data by scaling each feature to a range between 0 and 1\n",
    "scaler = RobustScaler()\n",
    "np_data = scaler.fit_transform(np_data_unscaled)\n",
    "\n",
    "# Set the sequence length - this is the timeframe used to make a single prediction\n",
    "sequence_length = 110\n",
    "\n",
    "# Prediction Index\n",
    "index_Close = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75566b8a-df42-4c85-a59b-a1efd9cb5387",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the training data into train and train data sets\n",
    "# As a first step, we get the number of rows to train the model on 80% of the data \n",
    "train_data_len = math.ceil(np_data.shape[0] * 0.8)\n",
    "\n",
    "# Create the training and test data\n",
    "train_data = np_data[0:train_data_len, :]\n",
    "test_data = np_data[train_data_len - sequence_length:, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7f07f00-fdb1-46ea-8ea3-dd2c514585b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The RNN needs data with the format of [samples, time steps, features]\n",
    "# Here, we create N samples, sequence_length time steps per sample, and 6 features\n",
    "def partition_dataset(sequence_length, data):\n",
    "    x, y = [], []\n",
    "    data_len = data.shape[0]\n",
    "    for i in range(sequence_length, data_len):\n",
    "        x.append(data[i-sequence_length:i,:]) #contains sequence_length values 0-sequence_length * columsn\n",
    "        y.append(data[i, index_Close]) #contains the prediction values for validation (3rd column = Close),  for single-step prediction\n",
    "    \n",
    "    \n",
    "    # Convert the x and y to numpy arrays\n",
    "    x = np.array(x)\n",
    "    y = np.array(y)\n",
    "    return x, y\n",
    "\n",
    "# Generate training data and test data\n",
    "x_train, y_train = partition_dataset(sequence_length, train_data)\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "x_test, y_test = partition_dataset(sequence_length, test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5baea1c-18b6-4289-9297-f587ac586163",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the shapes: the result is: (rows, training_sequence, features) (prediction value, )\n",
    "print(x_train.shape, y_train.shape)\n",
    "print(x_test.shape, y_test.shape)\n",
    "\n",
    "# Validate that the prediction value and the input match up\n",
    "# The last close price of the second input sample should equal the first prediction value\n",
    "print(x_test[1][sequence_length-1][index_Close])\n",
    "print(y_test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf980ea1-4b33-4d81-afc0-cf259d74e9ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_train)\n",
    "print(x_train.shape[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81000878-658f-49d3-8748-2e235052b41c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure the neural network model\n",
    "epochs = 5; batch_size = 1;\n",
    "\n",
    "# Model with n_neurons = inputshape Timestamps, each with x_train.shape[2] variables\n",
    "n_neurons = x_train.shape[1] * x_train.shape[2]\n",
    "model = Sequential()\n",
    "model.add(LSTM(n_neurons, return_sequences=False, input_shape=(x_train.shape[1], 1)))\n",
    "model.add(Dense(1))\n",
    "model.compile(optimizer=\"adam\", loss=\"mean_squared_error\")\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c35590c-29e1-435e-b372-92949857098e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape the data, so that we get an array with multiple test datasets\n",
    "x_test = np.array(x_test)\n",
    "x_test = np.reshape(x_test, (x_test.shape[0], x_test.shape[1], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a5f4cdb-abaa-4bdc-9d27-2a1bc955cf4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the predicted values\n",
    "predictions = model.predict(x_test)\n",
    "predictions = scaler.inverse_transform(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0884b5b-23f8-4235-98b7-7689e99ecc3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc5ba259-75a7-4a53-a058-9ca7b01fb618",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the root mean squarred error (RMSE) and the meadian error (ME)\n",
    "rmse = np.sqrt(np.mean(predictions - y_test) ** 2)\n",
    "me = np.median(y_test - predictions)\n",
    "print(\"me: \" + str(round(me, 4)) + \", rmse: \" + str(round(rmse, 4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "069c6628-b3da-4907-96e0-9804ab91a918",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the prediction data\n",
    "train = df[:train_data_len]\n",
    "valid = df[train_data_len:]\n",
    "valid.insert(1, \"Predictions\", predictions, True)\n",
    "fig, ax1 = plt.subplots(figsize=(32, 5), sharex=True)\n",
    "yt = train[[\"valid\"]]\n",
    "yv = valid[[\"valid\", \"Predictions\"]]\n",
    "ax1.tick_params(axis=\"x\", rotation=0, labelsize=10, length=0)\n",
    "plt.title(\"Predictions vs Ground Truth\", fontsize=18)\n",
    "plt.plot(yv[\"Predictions\"], color=\"#F9A048\")\n",
    "plt.plot(yv[\"valid\"], color=\"#A951DC\")\n",
    "plt.legend([\"Ground Truth\", \"Train\"], loc=\"upper left\")\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1709b3d2-c15e-4bca-bee2-d3fe70866d85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize the loss\n",
    "fig, ax = plt.subplots(figsize=(5, 5), sharex=True)\n",
    "plt.plot(history.history[\"loss\"])\n",
    "plt.title(\"Model loss\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "ax.xaxis.set_major_locator(plt.MaxNLocator(epochs))\n",
    "plt.legend([\"Train\", \"Test\"], loc=\"upper left\")\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4c16d34-ca55-4a30-840e-609ca09ee86d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Settings and Model Labels\n",
    "rolling_forecast_range = 30\n",
    "titletext = \"Forecast Chart Model A\"\n",
    "ms = [\n",
    "    [\"epochs\", epochs],\n",
    "    [\"batch_size\", batch_size],\n",
    "    [\"lstm_neuron_number\", n_neurons],\n",
    "    [\"rolling_forecast_range\", rolling_forecast_range],\n",
    "    [\"layers\", \"LSTM, DENSE(1)\"],\n",
    "]\n",
    "\n",
    "settings_text = \"\"\n",
    "lms = len(ms)\n",
    "for i in range(0, lms):\n",
    "    settings_text += ms[i][0] + \": \" + str(ms[i][1])\n",
    "    \n",
    "    if i < lms - 1:\n",
    "        settings_text = settings_text + \",  \"\n",
    "        \n",
    "new_df = df.filter([\"valid\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd123d70-3f6e-43dd-9725-4910ffa9f835",
   "metadata": {},
   "outputs": [],
   "source": [
    "last_values = new_df[-n_neurons:].values\n",
    "last_values_scaled = scaler.transform(last_values)\n",
    "X_input = []\n",
    "X_input.append(last_values_scaled)\n",
    "X_input = np.array(X_input)\n",
    "X_test = np.reshape(X_input, (X_input.shape[0], X_input.shape[1], 1))\n",
    "# shape von x_test = (1, 110, 1)\n",
    "pred_value = model.predict(X_input)\n",
    "print(pred_value)\n",
    "pred_value_unscaled = scaler.inverse_transform(pred_value)\n",
    "print(pred_value_unscaled)\n",
    "pred_value_f = round(pred_value_unscaled[0, 0], 4)\n",
    "print(pred_value_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f7e1e6d-7b57-4b19-8239-04ce235018da",
   "metadata": {},
   "outputs": [],
   "source": [
    "next_index = new_df.iloc[[-1]].index.values + 1\n",
    "print(next_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a945ae9f-24d1-40a9-a495-73c515cfd53c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making a Multi-Step Prediction\n",
    "for i in range(0, rolling_forecast_range):\n",
    "    last_values = new_df[-n_neurons:].values\n",
    "    last_values_scaled = scaler.transform(last_values)\n",
    "    X_input = []\n",
    "    X_input.append(last_values_scaled)\n",
    "    X_input = np.array(X_input)\n",
    "    X_test = np.reshape(X_input, (X_input.shape[0], X_input.shape[1], 1))\n",
    "    # shape von x_test = (1, 110, 1)\n",
    "    pred_value = model.predict(X_input)\n",
    "    pred_value_unscaled = scaler.inverse_transform(pred_value)\n",
    "    pred_value_f = round(pred_value_unscaled[0, 0], 4)\n",
    "    next_index = new_df.iloc[[-1]].index.values + 1\n",
    "    print(next_index)\n",
    "    new_df = new_df.append(pd.DataFrame({\"valid\": pred_value_f}, index=next_index))\n",
    "    new_df_length = new_df.size\n",
    "forecast = new_df[new_df_length - rolling_forecast_range : new_df_length].rename(\n",
    "    columns={\"valid\": \"Forecast\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a07317bf-8fa0-4581-b251-845121efaf2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15074a13-d1a6-450b-b433-84e936f2a94c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
